{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "img_split_for_cloud.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "7fMO28TUgL7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.collections import PatchCollection\n",
        "from skimage import io\n",
        "from skimage.segmentation import quickshift\n",
        "import glob\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTN6fIs9gPeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import functools\n",
        "from skimage import io\n",
        "from skimage.segmentation import quickshift\n",
        "import glob\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emE9yj1XgV2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yoZuGJ0jgYk6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH=\"drive/inter_iit/conv_data\"\n",
        "img_dir = os.path.join(PATH, \"sat\")\n",
        "label_dir = os.path.join(PATH, \"gt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtBfa-QWgavo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def scale_percentile(matrix):\n",
        "    \"\"\"Fixes the pixel value range to 2%-98% original distribution of values\"\"\"\n",
        "    orig_shape = matrix.shape\n",
        "    matrix = np.reshape(matrix, [matrix.shape[0]*matrix.shape[1], 3]).astype(float)\n",
        "    \n",
        "    # Get 2nd and 98th percentile\n",
        "    mins = np.percentile(matrix, 1, axis=0)\n",
        "    maxs = np.percentile(matrix, 99, axis=0) - mins\n",
        "    \n",
        "    matrix = (matrix - mins[None,:])/maxs[None,:]\n",
        "    matrix = np.reshape(matrix, orig_shape)\n",
        "    matrix = matrix.clip(0,1)\n",
        "    return matrix\n",
        "\n",
        "def scale_percentile_without_normalization(matrix):\n",
        "    \"\"\"Fixes the pixel value range to 2%-98% original distribution of values\"\"\"\n",
        "    orig_shape = matrix.shape\n",
        "    matrix = np.reshape(matrix, [matrix.shape[0]*matrix.shape[1], 3]).astype(float)\n",
        "    \n",
        "    # Get 2nd and 98th percentile\n",
        "    mins = np.percentile(matrix, 1, axis=0)\n",
        "    maxs = np.percentile(matrix, 99, axis=0) - mins\n",
        "    \n",
        "    matrix = (matrix - mins[None,:])/maxs[None,:]\n",
        "    matrix = np.reshape(matrix, orig_shape)\n",
        "    #matrix = matrix.clip(0,1)\n",
        "    return matrix\n",
        "def stretch_8bit(bands, lower_percent=2, higher_percent=98):\n",
        "    out = np.z|eros_like(bands).astype(np.float32)\n",
        "    for i in range(3):\n",
        "        a = 0\n",
        "        b = 1\n",
        "        c = np.percentile(bands[:, :, i], lower_percent)\n",
        "        d = np.percentile(bands[:, :, i], higher_percent)\n",
        "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
        "        t[t < a] = a\n",
        "        t[t > b] = b\n",
        "        out[:, :, i] = t\n",
        "    return out.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVSBeCpqgbTs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_filenames = []\n",
        "y_train_filenames = []\n",
        "for index in range( 14):\n",
        "  \n",
        "  x_train_filenames.append(os.path.join(img_dir, \"{}.png\".format(index)))\n",
        "  y_train_filenames.append(os.path.join(label_dir, \"{}.png\".format(index)))\n",
        "  #print(index)\n",
        "\n",
        "print(len(x_train_filenames))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbMYtUpdghoO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "display_num = 5\n",
        "nu=len(x_train_filenames)\n",
        "r_choices = np.random.choice(nu, display_num)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "for i in range(0, display_num * 2, 2):\n",
        "  img_num = r_choices[i // 2]\n",
        "  x_pathname = x_train_filenames[img_num]\n",
        "  y_pathname = y_train_filenames[img_num]\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 1)\n",
        "  print(io.imread(x_train_filenames[img_num])[...,0:3].shape)\n",
        "  plt.imshow((io.imread(x_pathname)[...,0:3]))\n",
        "  plt.title(\"Original Image\")\n",
        "  \n",
        "  example_labels = Image.open(y_pathname)\n",
        "  label_vals = np.unique(example_labels)\n",
        "  #print(np.unique(io.imread(y_train_filenames[img_num])))\n",
        "  plt.subplot(display_num, 2, i + 2)\n",
        "  plt.imshow(example_labels)\n",
        "  plt.title(\"Masked Image\")  \n",
        "  \n",
        "plt.suptitle(\"Examples of Images and their Masks\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZT66l82goGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH=\"drive/inter_iit/split_data\"\n",
        "img_dir = os.path.join(PATH, \"sat\")\n",
        "label_dir = os.path.join(PATH, \"gt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJmC1wz7gpY3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "h,w=256,256\n",
        "\n",
        "split_sat=[]\n",
        "split_gt=[]\n",
        "t=0\n",
        "for i in range(0, 14):\n",
        "  \n",
        "  img_num=i\n",
        "  x,y=0,0\n",
        "  x_pathname = x_train_filenames[img_num]\n",
        "  y_pathname = y_train_filenames[img_num]\n",
        "  im_sat=io.imread(x_pathname)[...,0:3]\n",
        "  im_gt=io.imread(y_pathname)[...,0:3]\n",
        "  n=i\n",
        "  print(i)\n",
        "  \n",
        "  while 1:\n",
        "    x=0\n",
        "    while 1:\n",
        "      \n",
        "      fname_lab=os.path.join(label_dir, \"{}_{}_{}.png\".format(n,x,y))\n",
        "      fname_img=os.path.join(img_dir, \"{}_{}_{}.png\".format(n,x,y))\n",
        "      a,b,c=im_sat[y:y+h, x:x+w].shape\n",
        "      c,d,f=im_gt[y:y+h, x:x+w].shape\n",
        "      \n",
        "      \n",
        "      if(a==256 and b==256 and c==256 and d==256):\n",
        "        \n",
        "        t=t+1\n",
        "        \n",
        "        #print(t)\n",
        "        if(t==1):\n",
        "          crop_img_x = im_sat[y:y+h, x:x+w]#.flatten()\n",
        "          a=crop_img_x.reshape(1,h*w*3)\n",
        "          #df_sat=pd.DataFrame(a)\n",
        "          crop_img_y = im_gt[y:y+h, x:x+w] \n",
        "          b=crop_img_y.reshape(1,h*w*3)\n",
        "          #df_gt=pd.DataFrame(b)\n",
        "          #print(\"dddddddddd\")\n",
        "        else:\n",
        "          crop_img_x = im_sat[y:y+h, x:x+w]#.flatten()\n",
        "          a=crop_img_x.reshape(1,h*w*3)\n",
        "          #temp=pd.DataFrame(a)\n",
        "          #df_sat = pd.concat([df_sat, temp], axis=0, ignore_index=True)\n",
        "          #plt.imsave(fname_img,crop_img_x)\n",
        "          #print(crop_img_y.shape)\n",
        "          split_sat.append(crop_img_x)\n",
        "\n",
        "          crop_img_y = im_gt[y:y+h, x:x+w]#.flatten()\n",
        "          b=crop_img_y.reshape(1,h*w*3)\n",
        "          #temp2=pd.DataFrame(b)\n",
        "          #df_gt = pd.concat([df_gt, temp2], axis=0, ignore_index=True)\n",
        "          #plt.imsave(fname_lab,crop_img_y)\n",
        "          split_gt.append(crop_img_y)\n",
        "      x=x+40\n",
        "     # print(x)\n",
        "      if(x>=750):\n",
        "        break\n",
        "    y=y+40\n",
        "    if(y>=750):\n",
        "      break\n",
        "      \n",
        "    \n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YovfBluQgsZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "split_sat = np.asarray(split_sat)\n",
        "split_gt = np.asarray(split_gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBoXmbbCgvQ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "img_shape = (256, 256, 3)\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfOxwTnqgy4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val= train_test_split(split_sat, split_gt, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wImuJUy_g0gf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_train_examples = len(x_train)\n",
        "num_val_examples = len(x_val)\n",
        "print(num_train_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SwYr-yqg119",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import keras\n",
        "import h5py\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "from keras.optimizers import Nadam\n",
        "from keras.callbacks import History\n",
        "import pandas as pd\n",
        "from keras.backend import categorical_crossentropy\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import random\n",
        "import threading\n",
        "from tensorflow.python.keras import layers\n",
        "from keras.models import model_from_json\n",
        "import tensorflow.contrib as tfcontrib\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras import backend as K\n",
        "from keras import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "564SpUKgg2vS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_block(input_tensor, num_filters):\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.Activation('relu')(encoder)\n",
        "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "  encoder = layers.BatchNormalization()(encoder)\n",
        "  encoder = layers.Activation('relu')(encoder)\n",
        "  return encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "  encoder = conv_block(input_tensor, num_filters)\n",
        "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "  \n",
        "  return encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "  decoder = layers.BatchNormalization()(decoder)\n",
        "  decoder = layers.Activation('relu')(decoder)\n",
        "  return decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ayhQOOeg5O8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=img_shape)\n",
        "\n",
        "# 256\n",
        "print(inputs.shape)\n",
        "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
        "# 128\n",
        "print(encoder0_pool.shape)\n",
        "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
        "# 64\n",
        "\n",
        "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
        "# 32\n",
        "\n",
        "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
        "# 16\n",
        "\n",
        "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "# 8\n",
        "\n",
        "center = conv_block(encoder4_pool, 1024)\n",
        "# center\n",
        "\n",
        "decoder4 = decoder_block(center, encoder4, 512)\n",
        "# 16\n",
        "\n",
        "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
        "# 32\n",
        "\n",
        "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
        "# 64\n",
        "\n",
        "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
        "# 128\n",
        "\n",
        "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
        "\n",
        "#encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
        "outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVdY7EFdg73Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = models.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s_Goz9lQg-KZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    # Flatten\n",
        "    y_true_f = tf.reshape(y_true, [-1])\n",
        "    y_pred_f = tf.reshape(y_pred, [-1])\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4gpCfHphA3j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22IZ7xJNhCv9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = losses.categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnXJgNqHhESh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jaccard_coef(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def jaccard_coef_int(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
        "\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def jaccard_coef_loss(y_true, y_pred):\n",
        "    return -K.log(jaccard_coef(y_true, y_pred)) + categorical_crossentropy(y_pred, y_true)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AxC56x2IhGhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_loss])\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4w00gd32hHlv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_model_path = 'drive/inter_iit/model/weights.hdf5'\n",
        "cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, monitor='val_dice_loss', save_best_only=True, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45cF6K0hhKqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9_K2sWo3hJqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_rows = 256 \n",
        "im_cols = 256\n",
        "x_test=x_val\n",
        "y_test=y_val\n",
        "\n",
        "im_shape = (im_rows, im_cols, 3)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "y_train = y_train.reshape(y_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "y_test = x_test.reshape(y_test.shape[0], *im_shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_W4pS4KhOG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(x_train[1].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rq2eMhiwhPwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRAYJEnjhRKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "batch_size=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjQTdgrxhSWD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "data_augmentation = True\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history=model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n",
        "                   epochs=epochs,\n",
        "                   validation_data=(x_test/255,y_test/255),\n",
        "                   validation_steps=int(np.ceil(num_val_examples / float(batch_size))),\n",
        "                   callbacks=[cp])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0JDO06CvhYgr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dice = history.history['dice_loss']\n",
        "val_dice = history.history['val_dice_loss']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, dice, label='Training Dice Loss')\n",
        "plt.plot(epochs_range, val_dice, label='Validation Dice Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Dice Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irdOIu82hau1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Alternatively, load the weights directly: model.load_weights(save_model_path)\n",
        "model = models.load_model(save_model_path, custom_objects={'bce_dice_loss': bce_dice_loss,\n",
        "                                                           'dice_loss': dice_loss})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-y61ASehcNK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BovsTXUlhe3p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's visualize some of the outputs \n",
        "#data_aug_iter = .make_one_shot_iterator()\n",
        "#next_element = data_aug_iter.get_next()\n",
        "\n",
        "# Running next element in our graph will produce a batch of images\n",
        "plt.figure(figsize=(10, 20))\n",
        "for i in range(5):\n",
        "  k=i\n",
        "  #batch_of_imgs, label = tf.keras.backend.get_session().run(next_element)\n",
        "  #img = batch_of_imgs[0]\n",
        "  predicted_label = model.predict(x_test)[k]\n",
        "\n",
        "  plt.subplot(5, 3, 3 * i + 1)\n",
        "  plt.imshow(x_test[k])\n",
        "  plt.title(\"Input image\")\n",
        "  \n",
        "  plt.subplot(5, 3, 3 * i + 2)\n",
        "  plt.imshow(y_test[k])\n",
        "  plt.title(\"Actual Mask\")\n",
        "  plt.subplot(5, 3, 3 * i + 3)\n",
        "  plt.imshow(predicted_label[:, :, :])\n",
        "  plt.title(\"Predicted Mask\")\n",
        "plt.suptitle(\"Examples of Input Image, Label, and Prediction\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}